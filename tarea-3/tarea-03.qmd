---
title: "Tarea 3: preprocesamiento"
format: html
editor: visual
---

Considera la siguiente cadena de preprocesamiento que vimos en clase:

```{r, message = FALSE}
library(tidyverse)
library(tidymodels)
library(broom)
source("../R/casas_traducir_geo.R")
set.seed(83)
casas_split <- initial_split(casas, prop = 0.75)
casas_entrena <- training(casas_split)
receta_casas <- recipe(precio_miles ~ 
           nombre_zona + 
           area_hab_m2 + area_garage_m2 + area_sotano_m2 + 
           area_lote_m2 + 
           año_construccion + 
           calidad_gral + calidad_garage + calidad_sotano + 
           num_coches  + 
           aire_acondicionado + condicion_venta, 
           data = casas_entrena) |> 
  step_filter(condicion_venta == "Normal") |> 
  step_select(-condicion_venta, skip = TRUE) |> 
  step_cut(calidad_gral, breaks = c(3, 5, 7, 8), 
           include_outside_range = TRUE) |>
  step_novel(nombre_zona, calidad_sotano, calidad_garage) |> 
  step_unknown(calidad_sotano, calidad_garage) |> 
  step_other(nombre_zona, threshold = 0.02, other = "otras") |> 
  step_mutate(area_sotano_m2 = ifelse(is.na(area_sotano_m2), 0, area_sotano_m2)) |> 
  step_mutate(area_garage_m2 = ifelse(is.na(area_garage_m2), 0, area_garage_m2)) |> 
  step_dummy(nombre_zona, calidad_gral, calidad_garage, calidad_sotano, aire_acondicionado) |> 
  step_interact(terms = ~ area_hab_m2:starts_with("calidad_gral")) |> 
  step_interact(terms = ~ area_hab_m2:starts_with("nombre_zona")) |> 
  step_interact(terms = ~ area_garage_m2:starts_with("calidad_garage")) |> 
  step_interact(terms = ~ area_sotano_m2: starts_with("calidad_sotano")) |>
  step_nzv(all_predictors(), freq_cut = 900 / 1, unique_cut = 0.5)

```

Entrenamos la receta y vemos cuántos casos y columnas tenemos:

```{r}
receta_casas_prep <- prep(receta_casas, verbose = TRUE)
datos_tbl <- juice(receta_casas_prep)
dim(datos_tbl)
```

*Pregunta 1*: ¿Cuántas variables originales usamos para este modelo, comparado con el número de entradas derivadas?

Usamos 6 variables independientes originales: **area_hab_m2**, **area_garage_m2**, **area_sotano_m2**, **area_lote_m2**, **año_construccion**, **num_coches** y 1 variable dependiente **precio_miles**

*Pregunta 2*: ¿qué variables fueron procesadas para producir entradas con codificación dummy? Extrae de *datos_tbl* las columnas que corresponden a *calidad_gral*. ¿Cuántas columnas hay y por qué? Puedes ver los nombres de las columnas haciendo:

```{r}
names(datos_tbl)
```

Se usaron las variables nombre_zona, calidad_gral, calidad_garage, calidad_sotano y aire_acondicionado para producir codificación dummy.

Hay 4 variables correspondientes a calidad general. El motivo es que cuando se hacen los cortes de calidad los rangos van de 0 a 3, de 3 a 5, de 5 a 7, de 7 a 8, y de 8 a 10, sin embargo el rango de 0 a 3 no es considerado ya que si la calidad general no entra dentro de los rangos previamente definidos, se puede inferir que corresponde al rango de calidad sin variable.

*Pregunta 3*: ¿qué entradas fueron creadas como interacciones de variables originales? Explica la razón de intentar utilizar estas interacciones. por ejemplo, area_hab y la zona.

Se crearon las interacciones 1) **area_hab_m2** con **calidad_gral**, 2) **area_hab_m2** con **nombre_zona**, 3) **area_garage_m2** con **calidad_garage**, y 4) **area_sotano_m2** con **calidad_sotano**, lo que generó una serie de variables del tipo var1xvar2, según sean las variables usadas.

Para el caso de **area_hab_m2** con **calidad_gral**, considero que fue creada porque generalmente la calidad de una casa está relacionada con el tamaño habitable, por lo que a mayor tamaño la calidad de la casa aumenta.

Para el caso de **area_hab_m2** con **nombre_zona**, es altamente probable que dependiendo de la zona donde se encuentre la casa, la zona habitable se vea influenciada. Esto es, que hay zonas donde generalmente hay casas pequeñas y zonas donde hay generalmente casas grandes.

Para el caso **area_garage_m2** con **calidad_garage**, es común que la calidad del garage de una casa esté relacionado con el área del mismo, por lo que mientras más grande sea el área de un garage es más probable que su calidad mejore.

Para el caso **area_sotano_m2** con **calidad_sotano**, sucede lo mismo que con la primera y tercera interacción, a mayor área de sótano es propable que su calidad aumente.

*Pregunta 4* Explica cómo se construye la interacción de area_hab_m2 con nombre de zona. ¿Cómo se ven las columnas correspondientes a esta interacción? ¿Por qué estas columnas tienen muchos ceros?

Dado que se crearon 16 variables dummy asociadas a los nombres de las zonas por ser una variable categórica, al establecer su interacción con **area_hab_m2** tenemos que crear una variable asociada a cada variable dummy, por lo que columnas dummy de **nombre_zona** donde hay 0's deberían tener asociado un valor de 0 en su interacción con **area_hab_m2**, y aquellas donde tienen un valor de 1's, el valor en su interacción debe ser del área habitable.

*Pregunta 5*: Ajusta un modelo y cuenta el número de coeficientes. La razón del preprocesamiento es mejorar el desempeño predictivo del modelo. ¿Por qué un modelo más complejo y con más coeficientes puede dar mejores resultados que uno más simple sin interacciones, por ejemplo? ¿Es por reducción de sesgo o de varianza?

```{r}
flujo_casas <- workflow() |> 
  add_recipe(receta_casas) |> 
  add_model(linear_reg() |> set_engine("lm"))
ajuste <- fit(flujo_casas, casas_entrena)
```

```{r}
ajuste |> tidy() |> 
  mutate(across(where(is.numeric), round, 2)) |> 
  select(term, estimate) 
```

Tenemos 62 coeficientes, 61 asociados a variables independientes y 1 asociado al intercepto. La razón por la que un modelo más complejo con más coeficientes puede dar un mejor resultado es que se consideran todos los datos y las relaciones que existen entre ellos, por lo que se puede explotar la distribución de los mismos para reducir el sesgo, sin embargo el precio que se paga es la varianza del modelo.

Finalmente, puedes hacer predicciones con este modelo como sigue:

```{r}
predict(ajuste, casas_entrena)
```

**Pregunta 7** (opcional) Quita la última línea de preprocesamiento step_nvz (que quita variables con varianza cercana a cero). ¿Qué pasa cuando intentas hacer predicciones? En este ejemplo particular, ¿qué columnas elimina este paso? ¿El objetivo de este filtro es reducir varianza o sesgo?

```{r}
new_receta_casas <- recipe(precio_miles ~ 
           nombre_zona + 
           area_hab_m2 + area_garage_m2 + area_sotano_m2 + 
           area_lote_m2 + 
           año_construccion + 
           calidad_gral + calidad_garage + calidad_sotano + 
           num_coches  + 
           aire_acondicionado + condicion_venta, 
           data = casas_entrena) |> 
  step_filter(condicion_venta == "Normal") |> 
  step_select(-condicion_venta, skip = TRUE) |> 
  step_cut(calidad_gral, breaks = c(3, 5, 7, 8), 
           include_outside_range = TRUE) |>
  step_novel(nombre_zona, calidad_sotano, calidad_garage) |> 
  step_unknown(calidad_sotano, calidad_garage) |> 
  step_other(nombre_zona, threshold = 0.02, other = "otras") |> 
  step_mutate(area_sotano_m2 = ifelse(is.na(area_sotano_m2), 0, area_sotano_m2)) |> 
  step_mutate(area_garage_m2 = ifelse(is.na(area_garage_m2), 0, area_garage_m2)) |> 
  step_dummy(nombre_zona, calidad_gral, calidad_garage, calidad_sotano, aire_acondicionado) |> 
  step_interact(terms = ~ area_hab_m2:starts_with("calidad_gral")) |> 
  step_interact(terms = ~ area_hab_m2:starts_with("nombre_zona")) |> 
  step_interact(terms = ~ area_garage_m2:starts_with("calidad_garage")) |> 
  step_interact(terms = ~ area_sotano_m2: starts_with("calidad_sotano"))
```

```{r}
new_receta_casas_prep <- prep(new_receta_casas, verbose = TRUE)
new_datos_tbl <- juice(new_receta_casas_prep)
dim(new_datos_tbl)
```

```{r}
names(new_datos_tbl)
```

```{r}
setdiff(names(new_datos_tbl), names(datos_tbl))
```

```{r}
new_flujo_casas <- workflow() |> 
  add_recipe(new_receta_casas) |> 
  add_model(linear_reg() |> set_engine("lm"))
ajuste <- fit(new_flujo_casas, casas_entrena)
```

```{r}
predict(ajuste, casas_entrena)
```

El error puede ser porque todas las variables que se eliminan corresponden a las variables creadas de las categorías *new*, y el propósito de esta categoría es representar categorías de calidad nunca antes vistas, por lo que la data de entrenamiento no contiene datos con esta categoría en sus respectivas variables y no logra ajustar los coeficientes correspondientes.
